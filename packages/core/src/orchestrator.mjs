// Orchestrator with long-run + self-heal/cost + hybrid-merge support                // íŒŒì¼ ëª©ì : ìë™ ì½”ë”© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
import { readFileSync, writeFileSync, existsSync } from "node:fs";                  // íŒŒì¼ ì½ê¸°/ì“°ê¸°/ì¡´ì¬í™•ì¸ì„ ìœ„í•œ node:fs ë„¤ì„ë“œ ì„í¬íŠ¸
import { execSync } from "node:child_process";                                      // git/gh ëª…ë ¹ ì‹¤í–‰ì„ ìœ„í•œ child_process ì„í¬íŠ¸
import path from "node:path";                                                       // ê²½ë¡œ ê³„ì‚° ìœ í‹¸
import fs from "node:fs";                                                           // mkdirSync ë“± ë™ê¸° FS ìœ í‹¸
import process from "node:process";                                                 // í™˜ê²½ë³€ìˆ˜Â·í”„ë¡œì„¸ìŠ¤ ì •ë³´ ì ‘ê·¼
import { loadPlugins } from "./tokens/registry.mjs";                                // í”ŒëŸ¬ê·¸ì¸ ë¡œë”(í† í°/í›… ì£¼ì…)
import { pickLLMAndAgent } from "./router.mjs";                                     // LLM/Agent ë¼ìš°íŒ… ê²°ì •
import { makeOpenAI, runOpenAI } from "./llm/openai.mjs";                           // OpenAI ì–´ëŒ‘í„°
import { makeGemini, runGemini } from "./llm/gemini.mjs";                           // Gemini ì–´ëŒ‘í„°
import { runWithClaude } from "./agents/claude.mjs";                                // Claude ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°
import { runWithCursor } from "./agents/cursor.mjs";                                // Cursor ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°

function nowIso(){ return new Date().toISOString(); }                               // ISO íƒ€ì„ìŠ¤íƒ¬í”„ í—¬í¼(ë¡œê·¸/ê¸°ë¡ìš©)

export async function runOrchestrator({ repoRoot, configPath, eventPath }) {        // ë©”ì¸ ì§„ì…ì : ë¦¬í¬ ë£¨íŠ¸/ì„¤ì •/ì´ë²¤íŠ¸ ê²½ë¡œ ì¸ì
  const cfg = JSON.parse(readFileSync(path.join(repoRoot, configPath), "utf8"));    // íˆ´í‚· ì„¤ì • JSON ë¡œë“œ
  const tools = cfg.tools || {};                                                    // ë„êµ¬ ì„¤ì •(ëª¨ë¸/CLI ë“±)
  const policy = cfg.policy || {};                                                  // ì •ì±…(í—ˆìš©/ê¸ˆì§€ ê¸€ë¡­, ê¸¸ì´ í•œë„ ë“±)
  const labelsCfg = cfg.labels || {};                                               // ë¼ë²¨ í‚¤ ì„¤ì •(run/highCost ë“±)
  const pluginsPaths = cfg.plugins || [];                                           // í”ŒëŸ¬ê·¸ì¸ ê²½ë¡œ ëª©ë¡
  const pipeline = cfg.pipeline || { commands: {} };                                // íŒŒì´í”„ë¼ì¸ ëª…ë ¹(ë¹Œë“œ/í…ŒìŠ¤íŠ¸ ë“±)

  const evt = JSON.parse(readFileSync(eventPath, "utf8"));                          // GitHub ì´ë²¤íŠ¸ í˜ì´ë¡œë“œ ë¡œë“œ
  const isIssue = !!evt.issue && !evt.comment;                                      // ì´ìŠˆì¸ì§€(ì½”ë©˜íŠ¸ê°€ ì•„ë‹Œì§€) íŒë³„
  const rawBody = (isIssue ? (evt.issue.body || "") : (evt.comment.body || "")).trim(); // /auto ì›ë¬¸ ì¶”ì¶œ
  const labels = (evt.issue?.labels || []).map(l => l.name || "");                  // ë¼ë²¨ëª… ë°°ì—´ ì¶”ì¶œ

  if (!rawBody.startsWith("/auto")) return { skipped: true };                       // /auto ì•„ë‹Œ ì´ë²¤íŠ¸ëŠ” ìŠ¤í‚µ
  if (!labels.includes(labelsCfg.run || "automation:run")) return { skipped: true };// í•„ìˆ˜ ë¼ë²¨ ì—†ìœ¼ë©´ ìŠ¤í‚µ

  const { tokens, hooks } = await loadPlugins(pluginsPaths, repoRoot);              // í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ(í† í° í•¸ë“¤ëŸ¬/í›… íšë“)
  const after = rawBody.replace(/^\/auto\s*/i, "");                                 // /auto ì ‘ë‘ì–´ ì œê±°
  const m = after.match(/^((?:[\w:-]+)\b\s*)+/i) || [""];                           // í† í° ì‹œí€€ìŠ¤(í‚¤ì›Œë“œ) ë§¤ì¹­
  const seq = (m[0] || "").trim().split(/\s+/).filter(Boolean);                    // í† í°ì„ ê³µë°± ë¶„ë¦¬í•˜ì—¬ ë°°ì—´í™”
  const rest = after.slice((m[0]||"").length).trim();                               // ë‚˜ë¨¸ì§€ ë³¸ë¬¸(ììœ  í”„ë¡¬í”„íŠ¸)

  const ctx = {                                                                     // ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸(ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒíƒœ)
    repoRoot, cfg, tools, policy, labels, pipeline,                                 // í™˜ê²½/ì •ì±…/ë¼ë²¨/íŒŒì´í”„ë¼ì¸
    tokens: seq, tokenFlags: {},                                                    // í† í° ëª©ë¡/í”Œë˜ê·¸
    userDemand: rest,                                                                // ì‚¬ìš©ì ìš”êµ¬(í”„ë¡¬í”„íŠ¸)
    llm: null, model: null, agent: null,                                            // ì„ íƒëœ LLM/ëª¨ë¸/ì—ì´ì „íŠ¸
    agentPrompt: "",                                                                 // ì—ì´ì „íŠ¸ì— ì¤„ ìµœì¢… í”„ë¡¬í”„íŠ¸
    planOnly: false, preferFast: false,                                             // í”Œëœ ì „ìš©/ë¹ ë¥¸ ëª¨ë¸ ì„ í˜¸
    longMode: false, budgetMinutes: null, budgetSteps: null,                        // ì¥ì‹œê°„ ëª¨ë“œ/ì˜ˆì‚°
    loopSummary: { startedAt: nowIso(), steps: [] },                                // ë£¨í”„ ìš”ì•½(ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€)
    usageTotals: { openai: { input:0, output:0 }, gemini: { input:0, output:0 } },  // í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
    diagnostics: { last: null },                                                    // ìµœê·¼ ì§„ë‹¨(ì—ëŸ¬ ë“±)
    prNumber: null,                                                                  // ìƒì„±ëœ PR ë²ˆí˜¸
    branch: null                                                                     // ì‘ì—… ë¸Œëœì¹˜ëª…
  };

  for (const t of seq) { const h = tokens.get(t.toLowerCase()); if (h) await h(ctx); } // í† í°ë³„ í•¸ë“¤ëŸ¬ ì‹¤í–‰(ì˜µì…˜/í”Œë˜ê·¸ ì„¸íŒ…)

  const highCost = labels.includes(labelsCfg.highCost || "automation:high-cost");  // ê³ ë¹„ìš© ë¼ë²¨ ìœ ë¬´
  const max = policy.hard_stop_chars_without_high_cost_label ?? 20000;             // ë¼ë²¨ ì—†ì„ ë•Œ ì…ë ¥ ìµœëŒ€ ê¸¸ì´
  const planThreshold = policy.plan_only_threshold_chars ?? 8000;                  // í”Œëœ ì „ìš© ì„ê³„ì¹˜
  if (!(ctx.tokenFlags?.force && highCost)) {                                      // force+ê³ ë¹„ìš©ì´ ì•„ë‹ˆë©´
    if (ctx.userDemand.length > max && !highCost)                                  // ì…ë ¥ ê¸¸ì´ ì œí•œ ì´ˆê³¼ ì‹œ
      throw new Error("Input too long without high-cost label.");                  // ì¦‰ì‹œ ì¤‘ë‹¨(ë¹„ìš© ë³´í˜¸)
  }
  ctx.planOnly = ctx.planOnly || (ctx.userDemand.length > planThreshold && !highCost); // ê¸¸ë©´ í”Œëœ ì „ìš©ìœ¼ë¡œ ê°•ë“±

  const route = pickLLMAndAgent({ userDemand: ctx.userDemand, planOnly: ctx.planOnly, tools, preferFast: ctx.preferFast }); // ë¼ìš°íŒ… ê²°ì •
  ctx.llm = route.llm; ctx.model = route.model; ctx.agent = route.agent;          // ì„ íƒ ê²°ê³¼ ì €ì¥

  for (const h of hooks.beforeLLM) await h(ctx);                                   // LLM í˜¸ì¶œ ì „ í›… ì‹¤í–‰

  const systemGuard = [                                                            // ì—ì´ì „íŠ¸ ê°€ë“œë ˆì¼(ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
    "[ì—ì´ì „íŠ¸ ê°€ë“œë ˆì¼]",
    `- í—ˆìš© ê²½ë¡œ: ${(policy.allowed_globs||["src/**","app/**","docs/**"]).join(", ")}`,
    `- ê¸ˆì§€ ê²½ë¡œ: ${(policy.forbidden_globs||[".env*","secrets/**",".git/**"]).join(", ")}`,
    "- .env* / ë¹„ë°€í‚¤ / .git ì€ ì½ê¸°Â·ì“°ê¸°ë„ ê¸ˆì§€",
    "- í…ŒìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì‹¤í–‰ ì „ëµ ì œì•ˆ",
    "- ë³€ê²½ì€ ì„¤ëª… ê°€ëŠ¥í•œ ì‘ì€ ì»¤ë°‹ ë‹¨ìœ„ ê¶Œì¥"
  ].join("\n");                                                                     // ê°€ë“œë ˆì¼ ë¬¸ìì—´ ë³‘í•©

  const content = [                                                                 // ì‚¬ìš©ì ìš”êµ¬/ì‚°ì¶œë¬¼ í…œí”Œë¦¿ ê²°í•©
    systemGuard, "\n[ì‚¬ìš©ì ìš”êµ¬]", ctx.userDemand, "\n[ì›í•˜ëŠ” ì‚°ì¶œë¬¼]",
    "- ë³€ê²½ ê°œìš”(ëª©ë¡)", "- íŒŒì¼ë³„ ìˆ˜ì • ê³„íš", "- ì•ˆì „ ì²´í¬ë¦¬ìŠ¤íŠ¸",
    ctx.planOnly ? "- (í”Œëœ ì „ìš©: ì‹¤í–‰ëª…ë ¹ ìƒëµ)" : "- ìµœì¢… ì‹¤í–‰í•  ìˆ˜ì • ë‹¨ê³„"
  ].join("\n");                                                                     // ìµœì¢… LLM ì…ë ¥ ë³¸ë¬¸

  async function genPrompt(){                                                       // LLM í˜¸ì¶œ ë˜í¼(ëª¨ë¸ë³„ ë¶„ê¸°)

  if (ctx.llm === "openai") {                                                     // OpenAI ì„ íƒ ì‹œ
    const { text, usage } = await runOpenAI({                                     // OpenAI Responses í˜¸ì¶œ
      client: makeOpenAI(process.env.OPENAI_API_KEY),                             // OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±(í‚¤ í•„ìš”)
      model: ctx.model, system: systemGuard, user: content,                       // ëª¨ë¸/ì‹œìŠ¤í…œ/ìœ ì € ì…ë ¥
      reasoning: { effort: ctx.planOnly ? "medium" : "high" }                     // ì¶”ë¡  ë…¸ë ¥ë„ ì„¤ì •
    });                                                                            // í˜¸ì¶œ ì¢…ë£Œ
    if (usage) { ctx.usageTotals.openai.input += (usage.input_tokens||0); ctx.usageTotals.openai.output += (usage.output_tokens||0); } // ì‚¬ìš©ëŸ‰ ëˆ„ì 
    return text;                                                                   // ì‘ë‹µ í…ìŠ¤íŠ¸ ë°˜í™˜
  } else {                                                                         // Gemini ìš°ì„  ê²½ë¡œ
    try {                                                                          // ì˜ˆì™¸ë¥¼ ì¡ì•„ ëŒ€ì²´(fallback)ë¡œ ì „í™˜í•©ë‹ˆë‹¤.
      const { text } = await runGemini({                                           // Gemini í˜¸ì¶œ(ì¬ì‹œë„ í¬í•¨)
        client: makeGemini(process.env.GEMINI_API_KEY),                            // Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        model: ctx.model,                                                          // ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©
        user: content                                                              // ì‚¬ìš©ì ì…ë ¥ ì „ë‹¬
      });                                                                          // í˜¸ì¶œ ì¢…ë£Œ
      return text;                                                                 // ì„±ê³µ ì‹œ í…ìŠ¤íŠ¸ ë°˜í™˜
    } catch (e) {                                                                  // ì‹¤íŒ¨ ì‹œ
      ctx.diagnostics.last = {                                                     // ì§„ë‹¨ ì •ë³´ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
        type: "llm-fallback",                                                      // ìœ í˜•: LLM ëŒ€ì²´
        from: "gemini",                                                            // ì› ê³µê¸‰ì
        to: "openai",                                                              // ëŒ€ì²´ ê³µê¸‰ì
        message: String(e?.message || e)                                           // ì—ëŸ¬ ë©”ì‹œì§€ ê¸°ë¡
      };                                                                           // ì§„ë‹¨ ê°ì²´ ì¢…ë£Œ
      const fallbackModel = (ctx.tools?.openai?.default) || "gpt-4o-mini";         // ì„¤ì •ì— ì •ì˜ëœ ê¸°ë³¸ OpenAI ëª¨ë¸ ì‚¬ìš©
      const { text, usage } = await runOpenAI({                                    // OpenAIë¡œ ëŒ€ì²´ í˜¸ì¶œ
        client: makeOpenAI(process.env.OPENAI_API_KEY),                            // OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        model: fallbackModel,                                                      // ëŒ€ì²´ ëª¨ë¸
        system: systemGuard,                                                       // ë™ì¼í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user: content,                                                             // ë™ì¼í•œ ì‚¬ìš©ì ì…ë ¥
        reasoning: { effort: ctx.planOnly ? "medium" : "high" }                    // ì¶”ë¡  ë…¸ë ¥ë„ ìœ ì§€
      });                                                                          // í˜¸ì¶œ ì¢…ë£Œ
      if (usage) {                                                                 // ì‚¬ìš©ëŸ‰ì´ ë³´ê³ ë˜ë©´
        ctx.usageTotals.openai.input += (usage.input_tokens||0);                   // ì…ë ¥ í† í°ì„ ëˆ„ì í•˜ê³ 
        ctx.usageTotals.openai.output += (usage.output_tokens||0);                 // ì¶œë ¥ í† í°ì„ ëˆ„ì í•©ë‹ˆë‹¤.
      }                                                                            // ì‚¬ìš©ëŸ‰ ëˆ„ì  ì¢…ë£Œ
      return text;                                                                 // ëŒ€ì²´ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    }                                                                              // catch ì¢…ë£Œ
  }                                                                                // ë¶„ê¸° ë
}                                                                                                                   // í•¨ìˆ˜ ë

  // === genPrompt (êµì²´) =========================================================
  async function genPrompt(){
    let text = "";
    try {
      if (ctx.llm === "openai") {
        const { text: t, usage } = await runOpenAI({
          client: makeOpenAI(process.env.OPENAI_API_KEY),
          model: ctx.model, system: systemGuard, user: content,
          reasoning: { effort: ctx.planOnly ? "medium" : "high" }
        });
        if (usage) {
          ctx.usageTotals.openai.input += (usage.input_tokens||0);
          ctx.usageTotals.openai.output += (usage.output_tokens||0);
        }
        text = (t || "").trim();
        if (!text) {
          const { text: tg } = await runGemini({
          client: makeGemini(process.env.GEMINI_API_KEY),
          model: ctx.model, user: content
        });
        text = (tg || "").trim();
        }
        } else {
          const { text: tg } = await runGemini({
          client: makeGemini(process.env.GEMINI_API_KEY),
          model: ctx.model, user: content
        });
        text = (tg || "").trim();
        if (!text) {
          const { text: to, usage } = await runOpenAI({
            client: makeOpenAI(process.env.OPENAI_API_KEY),
            model: ctx.model, system: systemGuard, user: content,
            reasoning: { effort: ctx.planOnly ? "medium" : "high" }
          });
          if (usage) {
            ctx.usageTotals.openai.input += (usage.input_tokens||0);
            ctx.usageTotals.openai.output += (usage.output_tokens||0);
          }
          text = (to || "").trim();
        }
      }
    } catch (e) {
      console.error("[genPrompt error]", e?.message || e);
      text = "";
    }

    if (!text) {
      const fallback = [
        "## ì‘ì—… ê°œìš”",
        "- Next.js(App Router) + ws ê¸°ë°˜ ì˜¤ëª©(15x15) ì‹¤ì‹œê°„ ë™ê¸°í™”",
        "- í—ˆìš© ê²½ë¡œ(app/, src/, docs/**)ë§Œ ìˆ˜ì •",
        "",
        "## íŒŒì¼ í”Œëœ(í•„ìˆ˜ ì‚°ì¶œë¬¼ ë°˜ì˜)",
        "- app/game/[roomId]/page.tsx: ë¼ìš°íŒ…/ì…ì¥/ë Œë”",
        "- src/ui/Board.tsx: ìº”ë²„ìŠ¤/ì…€ í´ë¦­ í•¸ë“¤ë§",
        "- src/ui/HUD.tsx: í„´/ìŠ¹ë¦¬/ë©”ì‹œì§€",
        "- src/lib/game/rules.ts: 5ëª© íŒì •(ê°€ë¡œ/ì„¸ë¡œ/ì–‘ëŒ€ê°)",
        "- src/lib/game/types.ts: íƒ€ì… ì •ì˜",
        "- src/state/useGameStore.ts: ìƒíƒœ(zustand/Context)",
        "- src/server/ws.ts: ws ì„œë²„/ë£¸/ë¸Œë¡œë“œìºìŠ¤íŠ¸",
        "- src/lib/net/messages.ts: ë©”ì‹œì§€ íƒ€ì…",
        "- tests/unit/wincheck.test.ts: ê·œì¹™ ë‹¨ìœ„í…ŒìŠ¤íŠ¸",
        "- tests/e2e/omok.spec.ts: (ê°€ëŠ¥ ì‹œ) e2e",
        "- docs/GAMEPLAY.md: ê·œì¹™/ë¡œì»¬ ì‹¤í–‰",
        "",
        "## ë‹¨ê³„",
        "1) íƒ€ì…/ê·œì¹™ â†’ 2) UI â†’ 3) ws â†’ 4) í…ŒìŠ¤íŠ¸/ë¬¸ì„œ",
        "ì»¤ë°‹ì€ ì‘ì€ ë‹¨ìœ„, ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë¡œ ìê°€ì¹˜ìœ ",
      ].join("\n");
      return fallback;
    }
    return text;
  }
  // === genPrompt ì´í›„ ê°€ë“œ (êµì²´) ==============================================
  ctx.agentPrompt = await genPrompt();
  if (!ctx.agentPrompt || !String(ctx.agentPrompt).trim()) {
    ctx.planOnly = true;
    console.log("[orchestrator] Empty agent prompt â†’ planOnly=true; agent run skipped.");
  }
  for (const h of hooks.afterLLM) await h(ctx);
  if (ctx.tokenFlags?.dryRun) return { dryRun: true, ctx };
  if (ctx.agent === "none" || ctx.planOnly) return { planOnly: true, ctx };                                                                                                   // *** í•µì‹¬ ë³€ê²½ ì¢…ë£Œ ***

  async function runOneStep(step) {                                                 // í•œ ë‹¨ê³„ ì‹¤í–‰(ì—ì´ì „íŠ¸â†’ì»¤ë°‹â†’í‘¸ì‹œ)
    for (const h of hooks.beforeAgent) await h(ctx);                                // ì—ì´ì „íŠ¸ ì „ í›…
    try {                                                                            // ì˜ˆì™¸ ì²˜ë¦¬ ì‹œì‘
      if (ctx.agent === "claude") await runWithClaude(ctx.agentPrompt, tools, policy); // Claude ì—ì´ì „íŠ¸ ì‹¤í–‰
      else await runWithCursor(ctx.agentPrompt, tools, policy);                     // Cursor ì—ì´ì „íŠ¸ ì‹¤í–‰
    } catch(e) {                                                                     // ì—ëŸ¬ ë°œìƒ ì‹œ
      console.log("[Agent error]", e.message);                                      // ì—ëŸ¬ ë©”ì‹œì§€ ë¡œê¹…
      ctx.diagnostics.last = { type: "agent-error", message: e.message };           // ì§„ë‹¨ ì •ë³´ ë³´ê´€
    }                                                                                // try/catch ë
    for (const h of hooks.afterAgent) await h(ctx);                                 // ì—ì´ì „íŠ¸ í›„ í›…
    checkpointCommit(`auto: checkpoint step ${step}`);                               // ì²´í¬í¬ì¸íŠ¸ ì»¤ë°‹ ì‹œë„
    try { execSync(`git push origin ${branch}`, { stdio: "inherit" }); } catch {}   // ë¸Œëœì¹˜ í‘¸ì‹œ(ì‹¤íŒ¨ ë¬´ì‹œ)
    ctx.loopSummary.steps.push({ step, at: new Date().toISOString() });             // ë‹¨ê³„ ë©”íƒ€ ëˆ„ì 
  }                                                                                  // í•¨ìˆ˜ ë

  if (ctx.longMode) {                                                                // ì¥ì‹œê°„ ëª¨ë“œ ë¶„ê¸°
    const maxMs = (ctx.budgetMinutes||60) * 60 * 1000;                               // ì‹œê°„ ì˜ˆì‚°(ms)
    const maxSteps = ctx.budgetSteps || 3;                                           // ë‹¨ê³„ ì˜ˆì‚°(ê¸°ë³¸ 3)
    for (let step=1; step<=maxSteps; step++) {                                       // ë‹¨ê³„ ë£¨í”„
      if (existsSync(cancelPath)) break;                                             // CANCEL íŒŒì¼ ìˆìœ¼ë©´ ì¤‘ë‹¨
      if ((Date.now()-start) > maxMs) break;                                         // ì‹œê°„ ì˜ˆì‚° ì´ˆê³¼ ì‹œ ì¤‘ë‹¨
      await runOneStep(step);                                                        // ë‹¨ê³„ ì‹¤í–‰
      if (!ctx.agentPrompt || typeof ctx.agentPrompt !== "string" || !ctx.agentPrompt.trim()) {
        ctx.agentPrompt = "Continue.";
      } // í”„ë¡¬í”„íŠ¸ ë³´ì •

    }                                                                                // ë£¨í”„ ë
  } else {                                                                           // ë‹¨ë°œ ëª¨ë“œ
    await runOneStep(1);                                                             // 1ë‹¨ê³„ë§Œ ì‹¤í–‰
  }                                                                                  // ë¶„ê¸° ë
  for (const h of hooks.beforePR) await h(ctx);                                      // PR ìƒì„± ì „ í›… ì‹¤í–‰

  const tokenList = (ctx.tokens||[]).join(", ") || "(none)";
  const labelList = labels.join(", ") || "(none)";
  const truncatedUserDemand = (ctx.userDemand || "").slice(0, 2000);
  const costLine = `OpenAI usage: in=${ctx.usageTotals.openai.input} out=${ctx.usageTotals.openai.output}`;

  const infoMd = [

    `## Auto-run Info`,
    ``,
    `- LLM: **${ctx.llm}** (${ctx.model})`,
    `- Agent: **${ctx.agent}**`,
    `- Branch: ${ctx.branch}`,
    `- Labels: ${labelList}`,
    `- Tokens: ${tokenList}`,
    `- ${costLine}`,
    ``,
    `## Prompt (truncated)`,
    "",
    "```",
    truncatedUserDemand,
    "```",
    "",
    ctx.longMode ? `> Long-run: budget ${ctx.budgetMinutes} min / ${ctx.budgetSteps} steps.` : ""
  ].join("\n");                                                                       // ë¬¸ìì—´ ê²°í•© ì™„ë£Œ

  const promptMd = [                                                                  // ì „ì²´ í”„ë¡¬í”„íŠ¸/ë§ˆì§€ë§‰ ì—ì´ì „íŠ¸ ì…ë ¥ ê¸°ë¡
    `# Original Prompt`,
    "",
    "```",
    ctx.userDemand,
    "```",
    "",
    "## Last Agent Prompt",
    "",
    "```",
    ctx.agentPrompt,
    "```"
  ].join("\n");                                                                       // ë¬¸ìì—´ ê²°í•© ì™„ë£Œ

  // âœ… ë””ë ‰í„°ë¦¬ ë³´ì¥ í›„ íŒŒì¼ ê²½ë¡œë¥¼ outDir ê¸°ë°˜ìœ¼ë¡œ ìƒì„±(í•µì‹¬ ìˆ˜ì • ë°˜ì˜)                                            // *** í•µì‹¬ ì €ì¥ ê²½ë¡œ ***
  const prBodyPath = path.join(outDir, `pr-body-${Date.now()}.md`);                  // PR ë³¸ë¬¸ íŒŒì¼ ê²½ë¡œ
  const promptBodyPath = path.join(outDir, `prompt-${Date.now()}.md`);               // í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
  writeFileSync(prBodyPath, infoMd, "utf8");                                         // PR ë³¸ë¬¸ íŒŒì¼ ì“°ê¸°
  writeFileSync(promptBodyPath, promptMd, "utf8");                                   // í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì“°ê¸°

  // === PR ìƒì„± ===
  const title = `auto: ${ctx.branch} [${ctx.llm}/${ctx.agent}] (tokens: ${tokenList})`;
  execSync(
    `gh pr create --title ${JSON.stringify(title)} --body-file ${JSON.stringify(prBodyPath)} --base main --head ${ctx.branch}`,
    { stdio: "inherit" }
  );

  // === ğŸ”§ FIX: PR ë²ˆí˜¸ ì•ˆì „ ì¡°íšŒ(gh pr view --head ì‚­ì œ) ===
  // (A) gh pr list ë¡œ ì¡°íšŒ
  const prNumber = execSync(
    `gh pr list -s all --head ${ctx.branch} --json number --jq '.[0].number // empty'`
  ).toString().trim();

  ctx.prNumber = prNumber || null;

  if (prNumber) {
    execSync(
      `gh pr comment ${prNumber} --body-file ${JSON.stringify(promptBodyPath)}`,
      { stdio: "inherit" }
    );
  }


  for (const h of hooks.afterPR) await h(ctx);                                       // PR ìƒì„± í›„ í›… ì‹¤í–‰

  return { success: true, branch: ctx.branch, long: ctx.longMode, usage: ctx.usageTotals, prNumber: ctx.prNumber }; // ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ë°˜í™˜
}                                                                                    // runOrchestrator ë
